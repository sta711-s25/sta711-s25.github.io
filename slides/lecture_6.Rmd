---
title: "Lecture 6: Maximum likelihood estimation for logistic regression"
author: "Ciaran Evans"
output: beamer_presentation
---

## Logistic regression

$$Y_i \sim Bernoulli(p_i)$$

$$\log \left( \frac{p_i}{1- p_i} \right) = \beta_0 + \beta_1 X_{i,1} + \cdots + \beta_k X_{i,k}$$
Suppose we observe independent samples $(X_1, Y_1),...,(X_n, Y_n)$. Write down the likelihood function

$$L(\beta | {\bf X}, {\bf Y}) \propto \prod \limits_{i=1}^n f(Y_i| \beta, X_i)$$


## Newton's method

## Newton's method for logistic regression

## Example

Suppose that $\log \left( \dfrac{p_i}{1 - p_i} \right) = \beta_0 + \beta_1 X_{i}$, and we have

$$\beta^{(r)} = \begin{bmatrix} -3.1 \\ 0.9 \end{bmatrix}, \hspace{1cm} U(\beta^{(r)}) = \begin{bmatrix} 9.16 \\ 31.91 \end{bmatrix},$$
$${\bf H}(\beta^{(r)}) = -\begin{bmatrix} 17.834 & 53.218 \\ 53.218 & 180.718 \end{bmatrix}$$

Use Newton's method to calculate $\beta^{(r + 1)}$ (you may use R or a calculator, you do not need to do the matrix arithmetic by hand).