---
title: "Class activity solutions"
format: html
editor: source
author: "Ciaran Evans"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=F)
knitr::opts_chunk$set(warning=F)
```

1.

```{r}
nsim <- 1000
wald_stats <- rep(NA, nsim)
lrt_stats <- rep(NA, nsim)

for(i in 1:nsim){
  n <- 100
  beta0 <- 0.5
  beta1 <- 0
  x <- rnorm(n)
  p <- exp(beta0 + beta1 * x)/(1 + exp(beta0 + beta1 * x))
  y <- rbinom(n, 1, p)
  
  m1 <- glm(y ~ x, family = binomial)

  # test statistics
  wald_stats[i] <- summary(m1)$coefficients[2,3]^2
  lrt_stats[i] <- m1$null.deviance - m1$deviance
}

grid_pts <- seq(0, 5, by=0.1)
plot(grid_pts, ecdf(wald_stats)(grid_pts), type="l",
     xlab = "x", ylab = "CDF of Wald statistics")
points(grid_pts, pchisq(grid_pts, 1), type="l", col="red")

plot(grid_pts, ecdf(lrt_stats)(grid_pts), type="l",
     xlab = "x", ylab = "CDF of LRT statistics")
points(grid_pts, pchisq(grid_pts, 1), type="l", col="red")
```


2.

```{r}
nsim <- 1000
wald_stats <- rep(NA, nsim)
lrt_stats <- rep(NA, nsim)

n <- 10
beta0 <- 0.5
beta1 <- 0

for(i in 1:nsim){
  x <- rnorm(n)
  p <- exp(beta0 + beta1 * x)/(1 + exp(beta0 + beta1 * x))
  y <- rbinom(n, 1, p)
  
  m1 <- glm(y ~ x, family = binomial)

  # test statistics
  wald_stats[i] <- summary(m1)$coefficients[2,3]^2
  lrt_stats[i] <- m1$null.deviance - m1$deviance
}

grid_pts <- seq(0, 5, by=0.1)
plot(grid_pts, ecdf(wald_stats)(grid_pts), type="l",
     xlab = "x", ylab = "CDF of Wald statistics", main = "n = 10")
points(grid_pts, pchisq(grid_pts, 1), type="l", col="red")

plot(grid_pts, ecdf(lrt_stats)(grid_pts), type="l",
     xlab = "x", ylab = "CDF of LRT statistics", main = "n = 10")
points(grid_pts, pchisq(grid_pts, 1), type="l", col="red")
```

```{r}
nsim <- 1000
wald_stats <- rep(NA, nsim)
lrt_stats <- rep(NA, nsim)

n <- 30
beta0 <- 0.5
beta1 <- 0

for(i in 1:nsim){
  x <- rnorm(n)
  p <- exp(beta0 + beta1 * x)/(1 + exp(beta0 + beta1 * x))
  y <- rbinom(n, 1, p)
  
  m1 <- glm(y ~ x, family = binomial)

  # test statistics
  wald_stats[i] <- summary(m1)$coefficients[2,3]^2
  lrt_stats[i] <- m1$null.deviance - m1$deviance
}

grid_pts <- seq(0, 5, by=0.1)
plot(grid_pts, ecdf(wald_stats)(grid_pts), type="l",
     xlab = "x", ylab = "CDF of Wald statistics", main = "n = 30")
points(grid_pts, pchisq(grid_pts, 1), type="l", col="red")

plot(grid_pts, ecdf(lrt_stats)(grid_pts), type="l",
     xlab = "x", ylab = "CDF of LRT statistics", main = "n = 30")
points(grid_pts, pchisq(grid_pts, 1), type="l", col="red")
```


3.

```{r}
plot(wald_stats, lrt_stats, xlab = "Wald statistics", ylab = "LRT statistics",
     main = "n = 30")
abline(a=0, b=1, col="red", lty = 2)
```

```{r}
nsim <- 1000
wald_stats <- rep(NA, nsim)
lrt_stats <- rep(NA, nsim)

for(i in 1:nsim){
  n <- 100
  beta0 <- 0.5
  beta1 <- 0
  x <- rnorm(n)
  p <- exp(beta0 + beta1 * x)/(1 + exp(beta0 + beta1 * x))
  y <- rbinom(n, 1, p)
  
  m1 <- glm(y ~ x, family = binomial)

  # test statistics
  wald_stats[i] <- summary(m1)$coefficients[2,3]^2
  lrt_stats[i] <- m1$null.deviance - m1$deviance
}

plot(wald_stats, lrt_stats, xlab = "Wald statistics", ylab = "LRT statistics",
     main = "n = 100")
abline(a=0, b=1, col="red", lty = 2)
```

As $n$ increases, the Wald and LRT statistics get closer.


4.

```{r}
nsim <- 1000
wald_stats <- rep(NA, nsim)
lrt_stats <- rep(NA, nsim)

n <- 100
beta0 <- 0.5
beta1 <- 0.5

for(i in 1:nsim){
  x <- rnorm(n)
  p <- exp(beta0 + beta1 * x)/(1 + exp(beta0 + beta1 * x))
  y <- rbinom(n, 1, p)
  
  m1 <- glm(y ~ x, family = binomial)

  # test statistics
  wald_stats[i] <- summary(m1)$coefficients[2,3]^2
  lrt_stats[i] <- m1$null.deviance - m1$deviance
}

grid_pts <- seq(0, 20, by=0.1)
plot(grid_pts, ecdf(wald_stats)(grid_pts), type="l",
     xlab = "x", ylab = "CDF of Wald statistics")
points(grid_pts, pchisq(grid_pts, 1), type="l", col="red")

plot(grid_pts, ecdf(lrt_stats)(grid_pts), type="l",
     xlab = "x", ylab = "CDF of LRT statistics")
points(grid_pts, pchisq(grid_pts, 1), type="l", col="red")
```

The Wald and LRT statistics are now much larger, generally, than we would expect from a $\chi^2_1$ distribution. This makes sense -- under the alternative, we would expect larger values of the test statistic, which give us a greater chance of rejecting $H_0$.

5.

```{r, warning=F, message=F}
nsim <- 1000
sample_sizes <- c(30, 50, 75, 100)
wald_stats_means <- rep(NA, length(sample_sizes))

for(j in 1:length(sample_sizes)){
  n <- sample_sizes[j]
  wald_stats <- rep(NA, nsim)
  
  for(i in 1:nsim){
    x <- rnorm(n)
    p <- exp(beta0 + beta1 * x)/(1 + exp(beta0 + beta1 * x))
    y <- rbinom(n, 1, p)
    
    m1 <- glm(y ~ x, family = binomial)
  
    # test statistics
    wald_stats[i] <- summary(m1)$coefficients[2,3]^2
  }
  
  wald_stats_means[j] <- mean(wald_stats)
}

plot(sample_sizes, wald_stats_means, type="l",
     xlab = "n", ylab ="E(W)")
```